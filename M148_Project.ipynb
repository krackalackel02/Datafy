{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw_Wf2WONQ3c"
   },
   "source": [
    "# **1. Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-ZTAN8pNVG0"
   },
   "source": [
    "## **Install**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nduDzYxUNdba",
    "outputId": "ba3fa7de-fc75-42c1-ff30-51e011f94dfe"
   },
   "outputs": [],
   "source": [
    "%pip install -q numpy\n",
    "%pip install -q scipy\n",
    "%pip install -q matplotlib\n",
    "%pip install -q nbstripout\n",
    "%pip install -q pandas\n",
    "%pip install -q fsspec\n",
    "%pip install -q huggingface_hub\n",
    "%pip install -q scikit-lego\n",
    "%pip install -q plotly\n",
    "%pip install -q xlrd\n",
    "%pip install -q -U kaleido\n",
    "%pip install -q --upgrade nbformat\n",
    "%pip install -q torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOrQ_EybNfz2"
   },
   "source": [
    "## **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5NlVUykNjU0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import time\n",
    "import random\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.subplots as sbplt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, rand_score, adjusted_rand_score, accuracy_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.linear_model import  Ridge, Lasso\n",
    "from itertools import product\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pio.renderers.default = 'notebook+pdf'\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOm7K3FjNkjN"
   },
   "source": [
    "# **2. Original Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu1YW_gFNmfz"
   },
   "source": [
    "## **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoXFNL7QNpOe",
    "outputId": "c1df99f0-9f2c-49ee-c8f3-ef700b964dea"
   },
   "outputs": [],
   "source": [
    "\n",
    "spotify_df = pd.read_csv(\"hf://datasets/maharshipandya/spotify-tracks-dataset/dataset.csv\")\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4Ds91MpNqN3"
   },
   "source": [
    "## **Data Characterstics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peNnOmazNtlS"
   },
   "source": [
    "### **Drop extra ID col**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0JaWDxWNu5V"
   },
   "outputs": [],
   "source": [
    "\n",
    "spotify_df = spotify_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gydx3OeBNwGH"
   },
   "source": [
    "### **Shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHG6tcfMN0Yk",
    "outputId": "1eb43f53-c1ee-45c7-e043-d03a7de38068"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Print out the features\n",
    "print(\"Features:\", spotify_df.columns.tolist())\n",
    "\n",
    "# Get the shape of the data\n",
    "print(\"Shape of the data:\", spotify_df.shape)\n",
    "spotify_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6e4dWF7N3SP"
   },
   "source": [
    "### **Missingness**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG3AyFeMN5UX"
   },
   "source": [
    "\n",
    "\n",
    "The `check_missingness` function provides a detailed analysis of missing values in the dataset and visualizes the distribution of missingness across variables. This step is essential for understanding data quality and guiding preprocessing strategies.\n",
    "\n",
    "#### **Practical Steps in Missingness Handling**\n",
    "1. **Identify Missing Values**:\n",
    "   - Calculates the percentage of missing values for each column, enabling a clear view of the data quality.\n",
    "   - Filters columns with non-zero missingness for focused analysis.\n",
    "\n",
    "2. **Overall Statistics**:\n",
    "   - Computes the total number of missing values and their percentage across the entire dataset, offering a summary of the dataset's completeness.\n",
    "\n",
    "3. **Visualization**:\n",
    "   - Generates a bar plot showing the percentage of missing values for columns with non-zero missingness.\n",
    "   - The visualization helps prioritize which columns need imputation, removal, or further inspection.\n",
    "\n",
    "4. **Binary Missingness Data**:\n",
    "   - Creates a binary representation of missing values (1 for missing, 0 for present), useful for downstream analysis such as identifying patterns in missing data.\n",
    "\n",
    "5. **Customizable Output**:\n",
    "   - Dynamically adjusts the visualization size based on the number of columns, ensuring readability.\n",
    "   - Handles empty DataFrames gracefully, providing clear feedback when no analysis is needed.\n",
    "\n",
    "#### **Outcome**\n",
    "By applying this function:\n",
    "- Missing values are systematically analyzed and quantified, offering a comprehensive view of data quality.\n",
    "- The visualizations assist in identifying variables with critical levels of missingness, helping to decide whether to impute, drop, or investigate further.\n",
    "- The dataset is better prepared for preprocessing, ensuring minimal disruptions during analysis or modeling.\n",
    "\n",
    "This function is a crucial step in maintaining dataset integrity, enabling informed decisions on how to handle missing data effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnmZT2aGN9c5",
    "outputId": "a7e8cd55-e41e-4131-a3c8-08848d253cd6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_missingness(df):\n",
    "    \"\"\"\n",
    "    Analyzes and visualizes missing values in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    dict: Analysis results including missingness percentages and statistics.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"The DataFrame is empty. No missingness to analyze.\")\n",
    "        return {\n",
    "            'total_missing': 0,\n",
    "            'total_missing_percent': 0,\n",
    "            'missing_by_column': pd.Series(dtype=float),\n",
    "            'missing_binary': pd.DataFrame(),\n",
    "            'missing_analysis_df': pd.DataFrame(),\n",
    "            'columns_with_missing': []\n",
    "        }\n",
    "\n",
    "    print(\"Analyzing missingness...\")\n",
    "\n",
    "    # Calculate missingness percentage\n",
    "    missing_prop_percent = df.isna().mean() * 100\n",
    "\n",
    "    # Create binary missingness DataFrame\n",
    "    missing_binary = df.isna().astype(int)\n",
    "\n",
    "    # Get total missingness\n",
    "    total_missing = df.isna().sum().sum()\n",
    "    total_missing_percent = (total_missing / (df.size)) * 100  # Use df.size for clarity\n",
    "\n",
    "    print(\"\\nPercentage of missing values per column (sorted in descending order):\")\n",
    "    non_zero_missing = missing_prop_percent[missing_prop_percent > 0]\n",
    "    print(non_zero_missing.sort_values(ascending=False))\n",
    "\n",
    "    # Create missing value DataFrame for visualization\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Variable': missing_prop_percent.index,\n",
    "        'Missing Percent': missing_prop_percent.values\n",
    "    }).sort_values('Missing Percent', ascending=False)\n",
    "\n",
    "    # Only show visualization if there are missing values\n",
    "    if total_missing > 0:\n",
    "        # Create visualization\n",
    "        fig = px.bar(\n",
    "            missing_df[missing_df['Missing Percent'] > 0],  # Filter to non-zero only\n",
    "            x='Variable',\n",
    "            y='Missing Percent',\n",
    "            labels={'Variable': 'Predictor Variables',\n",
    "                    'Missing Percent': '% Missing'},\n",
    "            title='Percentage of Missing Values by Variable',\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            font=dict(size=12),\n",
    "            xaxis_tickangle=-45,\n",
    "            height=max(400, min(700, len(missing_df) * 20)),  # Dynamic height adjustment\n",
    "            width=1000\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"\\nNo missing values found in the dataset.\")\n",
    "\n",
    "    return {\n",
    "        'total_missing': total_missing,\n",
    "        'total_missing_percent': total_missing_percent,\n",
    "        'missing_by_column': missing_prop_percent,\n",
    "        'missing_binary': missing_binary,\n",
    "        'missing_analysis_df': missing_df,\n",
    "        'columns_with_missing': missing_df[missing_df['Missing Percent'] > 0]['Variable'].tolist()\n",
    "    }\n",
    "\n",
    "check_missingness(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE1Iog4iN_QC"
   },
   "source": [
    "### **Duplicates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThuIBLU8OCZf"
   },
   "source": [
    "\n",
    "The `check_duplicates` function is designed to identify and analyze duplicate entries within a dataset, ensuring data integrity and consistency. Duplicates can arise from errors in data collection or redundant records, and addressing them is crucial for accurate analysis and modeling.\n",
    "\n",
    "#### **Practical Steps in Duplicate Handling**\n",
    "1. **Identify Exact Duplicates**:\n",
    "   - Finds rows where all column values are identical. These are flagged as exact duplicates to be removed if necessary.\n",
    "\n",
    "2. **Track-Specific Duplicates**:\n",
    "   - For the `track_id` column, identifies duplicate track entries where the same `track_id` appears multiple times. This ensures each track is represented uniquely in the dataset.\n",
    "\n",
    "3. **Statistical Insights**:\n",
    "   - Provides key metrics such as the minimum and maximum number of duplicates per `track_id` for a deeper understanding of the duplicate distribution.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - Generates a bar plot (sampled if necessary) to visually represent the distribution of duplicate counts across `track_id`. This helps highlight patterns or anomalies in the dataset.\n",
    "\n",
    "5. **Examples of Duplicates**:\n",
    "   - Outputs a small sample of duplicate entries to facilitate manual inspection and verification.\n",
    "\n",
    "#### **Outcome**\n",
    "By leveraging this function:\n",
    "- Duplicate entries can be systematically identified and visualized.\n",
    "- Insights into duplicate patterns enable informed decisions about data cleaning and preprocessing.\n",
    "- The dataset is prepared for further analysis, free from redundant or conflicting records.\n",
    "\n",
    "This practical approach ensures the dataset's uniqueness and reliability, a foundational step for building robust models and drawing meaningful insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMRKx1dqOFSS",
    "outputId": "5c86568b-d766-49e5-bbd8-00a39eb2b15c"
   },
   "outputs": [],
   "source": [
    "def check_duplicates(original, sample_size=100):\n",
    "   \"\"\"\n",
    "   Analyzes and visualizes duplicate entries in the DataFrame\n",
    "\n",
    "   Parameters:\n",
    "   df (pandas.DataFrame): Input DataFrame\n",
    "   sample_size (int): Number of samples to show in visualization\n",
    "\n",
    "   Returns:\n",
    "   tuple: (DataFrame without duplicates, duplicate analysis DataFrame)\n",
    "   \"\"\"\n",
    "   print(\"\\nAnalyzing duplicates...\")\n",
    "   df = original.copy()\n",
    "\n",
    "   # Find exact duplicates\n",
    "   duplicated_rows = df[df.duplicated(keep=False)]\n",
    "   duplicated_rows_sorted = duplicated_rows.sort_values(by='track_id')\n",
    "\n",
    "   print(f\"\\nFound {len(duplicated_rows)} exact duplicate rows\")\n",
    "\n",
    "   # Check for duplicate track IDs\n",
    "   duplicates = df[df['track_id'].duplicated(keep=False)]\n",
    "   print(f\"\\nFound {len(duplicates)} rows with duplicate track_ids\")\n",
    "\n",
    "   if len(duplicates) > 0:\n",
    "       duplicate_counts = df.groupby('track_id').size().loc[lambda x: x > 1]\n",
    "\n",
    "       # Create DataFrame for duplicates\n",
    "       duplicate_df = duplicate_counts.reset_index()\n",
    "       duplicate_df.columns = ['track_id', 'count']\n",
    "\n",
    "       # Print statistics\n",
    "       print(\"\\nDuplicate statistics:\")\n",
    "       print(f\"Min duplicates per track: {duplicate_df['count'].min()}\")\n",
    "       print(f\"Max duplicates per track: {duplicate_df['count'].max()}\")\n",
    "\n",
    "       # Only show visualization if there are duplicates to show\n",
    "       if len(duplicate_df) > 0:\n",
    "           # Create visualization\n",
    "           fig = px.bar(duplicate_df.sample(min(sample_size, len(duplicate_df))),\n",
    "                        x='track_id',\n",
    "                        y='count',\n",
    "                        title='Duplicate Track Counts (Sample)')\n",
    "\n",
    "           fig.update_layout(\n",
    "               xaxis_title=\"Track Id\",\n",
    "               yaxis_title=\"Duplicate Counts\",\n",
    "               xaxis_tickangle=-45\n",
    "           )\n",
    "\n",
    "           fig.show()\n",
    "\n",
    "       print(\"\\nExample of duplicates (first 5 tracks):\")\n",
    "       print(duplicates.sort_values(by='track_id').head())\n",
    "\n",
    "   else:\n",
    "       print(\"\\nNo duplicates found in dataset\")\n",
    "\n",
    "   return {\n",
    "       'total_exact_duplicates': len(duplicated_rows),\n",
    "       'total_track_id_duplicates': len(duplicates),\n",
    "       'duplicate_analysis': duplicate_df if 'duplicate_df' in locals() else None,\n",
    "       'example_duplicates': duplicates.sort_values(by='track_id') if len(duplicates) > 0 else None\n",
    "   }\n",
    "check_duplicates(spotify_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6R7nV2bOJP9"
   },
   "source": [
    "# **3. Data Clean**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKDFrzXeOLEP"
   },
   "source": [
    "## **Clean Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8YUleRZONMB"
   },
   "source": [
    "### **Mean Imputation**: **Handling Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl5xQ0I8OP34"
   },
   "source": [
    "#### *Theoretical Approach*\n",
    "To ensure the dataset is complete and ready for analysis, we need to handle missing values effectively. Missing data can lead to issues in both exploratory data analysis and modeling, such as biased estimates or algorithm errors.\n",
    "\n",
    "*Imputation Strategy*:\n",
    "- **Numeric Columns**: We use the mean to impute missing values in numeric columns. This approach minimizes bias for continuous variables and maintains the overall distribution of the data.\n",
    "- **Categorical Columns**: We use the mode to impute missing values in categorical columns. This ensures that the most frequent category is preserved, reducing the risk of introducing outliers or inconsistent labels.\n",
    "\n",
    "This strategy ensures the dataset remains representative of its original characteristics while minimizing potential disruptions caused by missing data.\n",
    "\n",
    "*Example Scenarios*:\n",
    "- **Numeric Feature Example**: Variables like `tempo` or `loudness`, which represent continuous measurements, are imputed with their mean to preserve their numerical consistency.\n",
    "- **Categorical Feature Example**: Variables like `track_genre` or `key` are imputed with the mode to reflect the most common attribute within the data.\n",
    "\n",
    "By applying these imputation techniques, we create a robust foundation for subsequent preprocessing and analysis steps.\n",
    "\n",
    "#### *Practical Implementation*\n",
    "While exploring the dataset, we observed that missing values were limited to labels such as `artists`, `album_name`, and `track_name`. These features are unlikely to directly impact the modeling process and had minimal missingness.\n",
    "\n",
    "As a result:\n",
    "- **Decision**: We dropped these columns (`artists`, `album_name`, and `track_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7zvAeGIOSl5"
   },
   "outputs": [],
   "source": [
    "def impute_missing_values(df):\n",
    "    \"\"\"\n",
    "    Handles missing values in the DataFrame:\n",
    "    - Drops specified columns with minimal missing values.\n",
    "    - For object (string) columns: uses mode.\n",
    "    - For numeric columns: uses mean.\n",
    "    - For boolean columns: replaces missing values with False (or mode if preferred).\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with missing values handled.\n",
    "    \"\"\"\n",
    "    # Define columns to drop\n",
    "    cols_to_drop = ['artists', 'album_name', 'track_name']\n",
    "\n",
    "    # Drop specified columns\n",
    "    df.drop(columns=cols_to_drop, errors='ignore',inplace=True)\n",
    "\n",
    "    # Handle missing values for remaining columns\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_object_dtype(df[column]):\n",
    "            # Impute missing values in string columns with the mode\n",
    "            if not df[column].mode().empty:  # Handle edge cases where mode might fail\n",
    "                df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "        elif pd.api.types.is_bool_dtype(df[column]):\n",
    "            # Impute missing values in boolean columns with False (or mode if preferred)\n",
    "            df[column].fillna(False, inplace=True)\n",
    "        elif pd.api.types.is_numeric_dtype(df[column]):\n",
    "            # Impute missing values in numeric columns with the mean\n",
    "            df[column].fillna(df[column].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4oV3OplOTz_"
   },
   "source": [
    "\n",
    "### **Removing duplicates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3Poht11OVyk"
   },
   "source": [
    "\n",
    "\n",
    "#### *Theoretical Approach*\n",
    "**Duplicate** records in a dataset can distort analysis, lead to biased results, and reduce the efficiency of algorithms by introducing redundant computations. To maintain data integrity and ensure the dataset accurately represents unique entities, we must systematically remove **duplicates**.\n",
    "\n",
    "*Duplicate Removal Strategy*:\n",
    "1. **Exact Duplicates**:\n",
    "   - These occur when all columns in a row are identical. Removing these ensures that each record contributes uniquely to the analysis.\n",
    "2. **Track-Specific Duplicates**:\n",
    "   - For features like `track_id`, which uniquely identify songs, retaining only the first occurrence of each ensures that the dataset focuses on distinct tracks, even if associated metadata differs slightly across records.\n",
    "\n",
    "By applying this strategy, we preserve the uniqueness and relevance of the dataset, making it more suitable for modeling and exploratory data analysis.\n",
    "\n",
    "#### *Practical Implementation*\n",
    "In our dataset, **duplicates** were addressed in two steps:\n",
    "1. **Exact Duplicates**:\n",
    "   - Removed rows where all columns were identical, ensuring there are no redundant entries.\n",
    "2. **Track-Specific Duplicates**:\n",
    "   - For the `track_id` column, only the first occurrence of each unique track was retained, as subsequent entries were likely repetitive or irrelevant.\n",
    "\n",
    "**Outcome**:\n",
    "This approach ensures that our dataset contains only unique songs, with each track represented exactly once. This step is critical for downstream tasks like feature engineering and modeling, where **duplicates** could otherwise bias predictions or metrics.\n",
    "\n",
    "This combination of theoretical considerations and practical execution guarantees a clean and reliable dataset for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bklOWcrOX4G"
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Removes duplicates by:\n",
    "    1. Removing exact duplicates.\n",
    "    2. Aggregating features with 'genre_' in their name using a logical OR operation.\n",
    "    3. Averaging the 'popularity' column for aggregated rows.\n",
    "    4. Retaining only the first entry's genres for each track ID.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with one-hot encoded genres.\n",
    "\n",
    "    Returns:\n",
    "    None (modifies DataFrame in-place).\n",
    "    \"\"\"\n",
    "    # Step 1: Remove exact duplicates\n",
    "    print(\"Num rows before removing duplicates:\", len(df))\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Num rows after removing exact duplicates:\", len(df))\n",
    "    total_track_id_duplicates = len(df) - df['track_id'].nunique()\n",
    "    print(\"Num rows involved in ID duplicates (including original rows):\", total_track_id_duplicates)\n",
    "    # Step 2: Identify boolean columns\n",
    "    bool_cols = [\n",
    "        col for col in df.columns\n",
    "        if col.startswith(('genre_', 'key_', 'mode_')) or col == 'explicit'\n",
    "    ]\n",
    "\n",
    "    # Step 3: Group by track_id and aggregate\n",
    "    grouped = df.groupby('track_id').agg(\n",
    "        {**{col: 'max' for col in bool_cols},  # Logical OR (Union) for genres\n",
    "         'popularity': 'mean',                    # Average popularity\n",
    "         **{col: 'first' for col in df.columns if col not in bool_cols + ['popularity', 'track_id']}}  # Keep first occurrence of other features\n",
    "    ).reset_index()\n",
    "\n",
    "    # Step 4: Drop the original rows\n",
    "    df.drop(df.index, inplace=True)\n",
    "\n",
    "    # Step 5: Append the aggregated data\n",
    "    for col in grouped.columns:\n",
    "        df[col] = grouped[col]\n",
    "    print(\"Num rows after aggreagting inexact duplicates:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwM4RW7wOZz3"
   },
   "source": [
    "### **Removing Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACnaXwqjObjE"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "#### *Theoretical Approach*\n",
    "Outliers in a dataset can significantly distort statistical analyses and model performance. These extreme values can arise from data entry errors, anomalies, or rare events and may bias results if not addressed appropriately.\n",
    "\n",
    "*Outlier Removal Strategy*:\n",
    "1. **Z-Score Method**:\n",
    "   - The Z-score measures how far a data point is from the mean in terms of standard deviations. A threshold value (commonly 3) is used to identify extreme values.\n",
    "   - Data points with Z-scores greater than the threshold are considered outliers.\n",
    "\n",
    "This method is effective for numeric features with roughly normal distributions and ensures that the remaining dataset reflects typical values.\n",
    "\n",
    "#### *Practical Implementation*\n",
    "In our dataset, outliers were removed from all numeric columns using the Z-score method:\n",
    "1. **Numeric Columns**:\n",
    "   - Z-scores were calculated for each numeric feature to identify values that deviate significantly from the mean.\n",
    "2. **Threshold**:\n",
    "   - A threshold of 3 was used, meaning values more than 3 standard deviations away from the mean were considered outliers.\n",
    "3. **Row Removal**:\n",
    "   - Rows containing outliers in any numeric column were dropped to ensure data consistency.\n",
    "\n",
    "**Outcome**:\n",
    "This process eliminated extreme values, reducing noise and improving the quality of the dataset. By removing outliers, we ensure that subsequent analyses and models are not skewed by anomalous data points.\n",
    "\n",
    "This approach is crucial for datasets with features like `tempo` or `loudness`, where extreme values might misrepresent typical song characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJ6WKAdvOdT3"
   },
   "outputs": [],
   "source": [
    "def remove_outliers(df, threshold=3):\n",
    "    \"\"\"\n",
    "    Removes outliers from numeric columns in-place using z-score method\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame\n",
    "    threshold (int): Z-score threshold for outlier detection\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Get numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # Calculate z-scores for numeric columns\n",
    "    z_scores = sp.stats.zscore(df[numeric_columns])\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "\n",
    "    # Create mask for rows to keep\n",
    "    keep_mask = (abs_z_scores < threshold).all(axis=1)\n",
    "\n",
    "    # Drop rows with outliers in-place\n",
    "    drop_track_idx = df.index[~keep_mask]\n",
    "    df.drop(index=drop_track_idx, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pNbdTfNOeXL"
   },
   "source": [
    "\n",
    "### **One-Hot Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3lMrfWvOgpc"
   },
   "source": [
    "\n",
    "#### *Theoretical Approach*\n",
    "Categorical variables in datasets often need to be converted into a numerical format for use in machine learning models. One-hot encoding is a common technique that transforms categorical variables into binary features, preserving the categorical information while ensuring compatibility with numerical algorithms.\n",
    "\n",
    "*One-Hot Encoding Strategy*:\n",
    "1. **Binary Features**:\n",
    "   - Each unique category in a column is represented as a new binary feature (column). A value of 1 indicates the presence of that category, while 0 indicates its absence.\n",
    "2. **Custom Labels**:\n",
    "   - For specific features like `key` or `mode`, meaningful labels are assigned to ensure interpretability.\n",
    "\n",
    "This approach allows models to learn from categorical data without imposing unintended ordinal relationships between categories.\n",
    "\n",
    "#### *Practical Implementation*\n",
    "In our dataset, one-hot encoding was applied to key categorical variables:\n",
    "1. **Key Encoding**:\n",
    "   - The `key` column, representing musical keys, was mapped to descriptive labels (e.g., `C`, `D♯/E♭`).\n",
    "   - Negative values such as `-1` were treated as `0` to represent \"No Key\" for consistency.\n",
    "2. **Mode Encoding**:\n",
    "   - The `mode` column, representing whether a track is in a major or minor key, was encoded into two binary features: `Minor` and `Major`.\n",
    "3. **Track Genre Encoding**:\n",
    "   - The `track_genre` column was encoded dynamically to reflect all unique genres in the dataset, ensuring a scalable and adaptable approach.\n",
    "\n",
    "**Outcome**:\n",
    "By applying one-hot encoding, categorical data was transformed into a numerical format while preserving interpretability. This step ensures compatibility with machine learning algorithms and provides clarity in feature importance analysis.\n",
    "\n",
    "#### *Benefits of One-Hot Encoding*:\n",
    "- Avoids introducing unintended ordinal relationships between categories.\n",
    "- Facilitates clear model interpretation, especially with labeled binary features.\n",
    "- Ensures numerical compatibility across all features for preprocessing and modeling.\n",
    "\n",
    "This implementation creates a dataset that retains the original information from categorical variables while being fully ready for analysis and modeling tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziZT5UQnOmOc"
   },
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode(df, columns_with_labels):\n",
    "    \"\"\"\n",
    "    One-hot encodes columns into binary features with descriptive labels.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame\n",
    "    columns_with_labels (dict): Dictionary where keys are column names and values are\n",
    "                               dictionaries mapping values to their labels\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with new binary columns\n",
    "    \"\"\"\n",
    "    columns_to_drop = []\n",
    "    for col, value_labels in columns_with_labels.items():\n",
    "        columns_to_drop.append(col)\n",
    "        # For key column, replace -1 with 0 first\n",
    "        if col == 'key':\n",
    "            df[col] = df[col].replace(-1, 0)\n",
    "\n",
    "        # Create binary columns for each value's label\n",
    "        for value, label in value_labels.items():\n",
    "            if col == 'key' and value == -1:\n",
    "                continue  # Skip 'No Key' since we're treating it as 0/C\n",
    "\n",
    "            new_col = f\"{col}_{label}\"\n",
    "            df[new_col] = (df[col] == value)  # Removed .astype(int)\n",
    "\n",
    "    columns_to_drop = list(set(columns_to_drop))\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "def encode(df):\n",
    "    track_genre_values = df['track_genre'].unique()\n",
    "    track_genre_map = {track_genre: track_genre for track_genre in track_genre_values}\n",
    "    # Define labels for classification columns\n",
    "    columns_with_labels = {\n",
    "        'key': {\n",
    "            0: 'C',\n",
    "            1: 'C♯/D♭',\n",
    "            2: 'D',\n",
    "            3: 'D♯/E♭',\n",
    "            4: 'E',\n",
    "            5: 'F',\n",
    "            6: 'F♯/G♭',\n",
    "            7: 'G',\n",
    "            8: 'G♯/A♭',\n",
    "            9: 'A',\n",
    "            10: 'A♯/B♭',\n",
    "            11: 'B'\n",
    "        },\n",
    "        'mode': {\n",
    "            0: 'Minor',\n",
    "            1: 'Major'\n",
    "        },\n",
    "        # 'time_signature': {\n",
    "        #     3: 'ts_3/4',\n",
    "        #     4: 'ts_4/4',\n",
    "        #     5: 'ts_5/4',\n",
    "        #     6: 'ts_6/4',\n",
    "        #     7: 'ts_7/4',\n",
    "\n",
    "        # },\n",
    "        'track_genre':\n",
    "            track_genre_map\n",
    "\n",
    "    }\n",
    "\n",
    "    one_hot_encode(df, columns_with_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIipJLwoOnrL"
   },
   "source": [
    "### **Bool Conversion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smus_lzEOpap"
   },
   "source": [
    "\n",
    "#### *Theoretical Approach*\n",
    "Boolean data types (True/False) often represent binary states or conditions in datasets. While boolean representations are intuitive for human understanding, numerical representations (e.g., 1/0) are preferred by many machine learning algorithms, including logistic regression, which inherently models probabilities and requires numerical input.\n",
    "\n",
    "*Boolean Conversion Strategy*:\n",
    "1. **Boolean to Integer (1/0)**:\n",
    "   - Logistic regression and other numerical algorithms require binary features in numerical format.\n",
    "   - Example: True → 1, False → 0.\n",
    "2. **Integer (1/0) to Boolean**:\n",
    "   - In certain stages, such as post-processing or interpretability analysis, numerical outputs may need to be converted back to boolean values for better human understanding.\n",
    "   - Example: 1 → True, 0 → False.\n",
    "\n",
    "This strategy ensures compatibility with machine learning algorithms while retaining flexibility for interpretability when required.\n",
    "\n",
    "#### *Practical Implementation*\n",
    "In our dataset, boolean conversion was implemented to address specific requirements:\n",
    "1. **Boolean to Integer for Logistic Regression**:\n",
    "   - Features such as `is_explicit` or `is_popular` were converted to numerical format to enable seamless integration with logistic regression models, which require numerical input for binary classification tasks.\n",
    "2. **Integer to Boolean for Interpretability**:\n",
    "   - After model predictions or feature engineering processes, numerical outputs were converted back to boolean format for clearer human interpretation.\n",
    "\n",
    "**Outcome**:\n",
    "This process facilitates smooth preprocessing and modeling by converting boolean features to numerical format when needed, ensuring compatibility with algorithms like logistic regression while maintaining the ability to revert for interpretability.\n",
    "\n",
    "#### *Benefits of Boolean Conversion*:\n",
    "- Ensures compatibility with logistic regression and other machine learning algorithms requiring numerical input.\n",
    "- Preserves interpretability by allowing conversions back to boolean format when needed.\n",
    "- Provides flexibility to adapt boolean features for various stages of the data processing pipeline.\n",
    "\n",
    "By dynamically converting boolean columns to integers and vice versa, this function ensures the dataset is ready for both machine learning tasks and human interpretation, bridging the gap between raw data and analytical requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bI2Nl1OnOq-V"
   },
   "outputs": [],
   "source": [
    "def convert_to_bool(df, conv_bool_to_int):\n",
    "    \"\"\"\n",
    "    Converts all boolean columns in DataFrame to integers (1/0) or vice versa\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame\n",
    "    conv_bool_to_int (bool): If True, converts bool to int. If False, converts int to bool\n",
    "    \"\"\"\n",
    "    bool_columns = df.select_dtypes(include=bool).columns\n",
    "\n",
    "    if conv_bool_to_int:\n",
    "        for col in bool_columns:\n",
    "            df[col] = df[col].astype(int)\n",
    "    else:\n",
    "        for col in bool_columns:\n",
    "            df[col] = df[col].astype(bool)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp6oLkdlOsjL"
   },
   "source": [
    "### **Final Function: clean_data()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bpVzxOnOt5y"
   },
   "source": [
    "The `clean_data` function serves as a comprehensive pipeline that integrates all essential cleaning methods to prepare the dataset for analysis and modeling. This modular design allows for flexibility in enabling or disabling specific steps based on the dataset's requirements.\n",
    "\n",
    "#### **Steps in the Cleaning Pipeline**\n",
    "1. **Duplicate Removal**:\n",
    "   - Calls the `remove_duplicates` function to eliminate exact and track-specific duplicates, ensuring that each record is unique.\n",
    "   - Uses `check_duplicates` to verify the cleaning process.\n",
    "\n",
    "2. **Outlier Removal (Optional)**:\n",
    "   - If the `rmOutliers` flag is set to `True`, applies the `remove_outliers` function to eliminate extreme values from numeric columns.\n",
    "\n",
    "3. **Imputation**:\n",
    "   - Calls the `impute_missing_values` function to handle missing values by imputing with the mean for numeric columns and the mode for categorical columns.\n",
    "\n",
    "4. **Missingness Check**:\n",
    "   - Uses `check_missingness` to analyze and visualize the extent of missing data, ensuring that all missing values have been addressed appropriately.\n",
    "\n",
    "5. **One-Hot Encoding (Optional)**:\n",
    "   - If the `oneHot` flag is set to `True`, applies the `encode` function to transform categorical features into binary columns for compatibility with machine learning models.\n",
    "\n",
    "6. **Boolean Conversion**:\n",
    "   - Calls the `convert_to_bool` function to convert boolean columns into integers (1/0) or revert integers back to boolean, depending on the `conv_bool_to_int` flag.\n",
    "\n",
    "7. **Column Renaming (Optional)**:\n",
    "   - If the `rename_columns` flag is set to `True`, renames specific columns for clarity or standardization.\n",
    "\n",
    "#### **Outcome**\n",
    "The `clean_data` function ensures that the dataset is systematically cleaned and transformed, making it suitable for both exploratory analysis and advanced modeling tasks. By combining all cleaning methods into a single pipeline, this function enhances efficiency, consistency, and flexibility in preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZ7wVERZOwLl"
   },
   "outputs": [],
   "source": [
    "def clean_data(orginal, oneHot=True, rmOutliers=False,conv_bool_to_int=False,rename_columns=False):\n",
    "    cleaned = orginal.copy()\n",
    "    if oneHot: encode(cleaned)\n",
    "    remove_duplicates(cleaned)\n",
    "    check_duplicates(cleaned)\n",
    "    if rmOutliers: remove_outliers(cleaned)\n",
    "    impute_missing_values(cleaned)\n",
    "    check_missingness(cleaned)\n",
    "    convert_to_bool(cleaned,conv_bool_to_int)\n",
    "    if rename_columns: cleaned.rename(columns={'track_id': 'id','track_genre':'genre'}, inplace=True)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URouGwNUOxtr"
   },
   "source": [
    "## **Clean()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5KoX4nA_OzJb",
    "outputId": "eb0d46d5-9544-434f-ee37-3e83320339ba"
   },
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "spotify_df_cleaned = clean_data(spotify_df)\n",
    "spotify_df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zyxt2FTO1XP"
   },
   "source": [
    "# **4. Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYqHSlU9O2s_"
   },
   "source": [
    "\n",
    "## **Correlation Analysis Between Popularity and Numeric Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdkcFdSEO4eV"
   },
   "source": [
    "### **Bar Chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI1U4y5aO6dT"
   },
   "source": [
    "This analysis explores the relationships between the popularity of tracks and other numeric features in the dataset. By calculating Pearson correlation coefficients, we quantify the strength and direction of these relationships.\n",
    "\n",
    "The process involves creating a correlation matrix that identifies how strongly each numeric feature relates to popularity. Instead of visualizing the entire matrix, we focus on plotting a bar chart to highlight the most important correlations. This approach makes it easier to interpret and prioritize features based on their influence on popularity.\n",
    "\n",
    "#### Key Steps:\n",
    "1. **Data Preparation**:\n",
    "   - Filter numeric columns to ensure only relevant features are included in the analysis.\n",
    "   - Handle missing data by ensuring sufficient non-NaN values for meaningful calculations.\n",
    "\n",
    "2. **Correlation Calculation**:\n",
    "   - Compute Pearson correlation coefficients between `popularity` and other numeric features.\n",
    "   - Store the results in a structured format for visualization.\n",
    "\n",
    "3. **Bar Chart Visualization**:\n",
    "   - Display the correlations as a bar chart where:\n",
    "     - Features are shown on the x-axis.\n",
    "     - Correlation coefficients are shown on the y-axis.\n",
    "   - A color gradient is applied to emphasize the strength of the correlation.\n",
    "\n",
    "The bar chart provides an intuitive view of which features have strong positive or negative correlations with popularity. Features with higher absolute correlations can be prioritized for further analysis or modeling. This step offers a data-driven basis for understanding the factors influencing a track's success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sp-xy4bO9aZ",
    "outputId": "fec0313a-039f-44c9-ade7-d29f33bde35b"
   },
   "outputs": [],
   "source": [
    "numeric_df = spotify_df_cleaned.select_dtypes(include=[np.number])\n",
    "# Initialize an empty dictionary to store correlations\n",
    "correlation_data = {}\n",
    "\n",
    "# Calculate correlation coefficients between popularity and other numeric variables\n",
    "for column in numeric_df.columns:\n",
    "    if column != 'popularity':  # Skip popularity itself\n",
    "        # Ensure the column has at least two valid (non-NaN) values\n",
    "        if numeric_df[column].notna().sum() >= 2:\n",
    "            corr, _ = sp.stats.pearsonr(numeric_df['popularity'], numeric_df[column])\n",
    "            correlation_data[column] = corr\n",
    "        else:\n",
    "            print(f\"Skipping {column} due to insufficient data for correlation calculation.\")\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "correlation_df = pd.DataFrame(list(correlation_data.items()), columns=['Feature', 'Correlation'])\n",
    "correlation_df = correlation_df.sort_values(by=\"Correlation\", ascending=False)\n",
    "\n",
    "# Plotting with Plotly Express\n",
    "fig = px.bar(\n",
    "    correlation_df,\n",
    "    x='Feature',\n",
    "    y='Correlation',\n",
    "    title='Correlation between Popularity and Other Features',\n",
    "    labels={'Feature': 'Feature', 'Correlation': 'Correlation with Popularity'},\n",
    "    template='plotly_white',\n",
    "    color='Correlation',\n",
    "    color_continuous_scale=px.colors.sequential.Sunset\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Feature\",\n",
    "    yaxis_title=\"Correlation with Popularity\",\n",
    "    xaxis_tickangle=90,\n",
    "    height=600,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mcrX3poO_W5"
   },
   "source": [
    "### **Heat Map**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lagI9o0zPBxT"
   },
   "source": [
    "\n",
    "\n",
    "To visually represent the results, a heat map is generated from the correlation matrix. This allows for quick identification of features with strong positive or negative correlations with popularity, providing insights into the factors that might influence a track's success. For example, features such as tempo, danceability, or energy could exhibit significant correlations with popularity.\n",
    "\n",
    "The heat map provides an intuitive way to understand the structure of the data, highlighting the most influential features. This step is crucial for feature selection and serves as a foundation for predictive modeling and further exploratory analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVUTYLnhPDHZ",
    "outputId": "4b8505d7-7dd2-4b86-a44a-4ca0dc75b7f7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set up numerical columns\n",
    "numerical_columns = spotify_df_cleaned.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = spotify_df_cleaned[numerical_columns].corr()\n",
    "\n",
    "# Create the heatmap using Plotly Express\n",
    "fig = px.imshow(\n",
    "    corr_matrix,\n",
    "    labels={'x': 'Features', 'y': 'Features', 'color': 'Correlation'},\n",
    "    x=numerical_columns,\n",
    "    y=numerical_columns,\n",
    "    color_continuous_scale=px.colors.diverging.RdBu,  # Use a diverging colorscale like RdBu\n",
    "    title='Correlation Matrix: Popularity vs Other Variables'\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    title_font_size=18,\n",
    "    xaxis_tickangle=45,\n",
    "    height=700,\n",
    "    width=700\n",
    ")\n",
    "\n",
    "# Display the heatmap\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCVq2xWOPFDf"
   },
   "source": [
    "\n",
    "### **Histograms of numeric features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO6MNP_APHmu"
   },
   "source": [
    "\n",
    "Histograms are an essential tool for exploratory data analysis (EDA), providing insights into the distribution of numeric variables in the dataset. By plotting histograms for each numeric feature, we can achieve the following:\n",
    "\n",
    "1. **Understand Data Distribution**:\n",
    "   - Visualize how each numeric variable is distributed (e.g., normal, skewed, uniform).\n",
    "   - Identify if the data is centered around specific values or spread out across a range.\n",
    "\n",
    "2. **Detect Outliers**:\n",
    "   - Highlight extreme values that might affect the analysis or modeling process.\n",
    "   - Determine whether these outliers are valid or the result of errors.\n",
    "\n",
    "3. **Assess Data Quality**:\n",
    "   - Check for issues such as missing data or irregular value distributions.\n",
    "   - Confirm the range of values aligns with expectations for each feature.§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ty_LDRAQPMuc"
   },
   "outputs": [],
   "source": [
    "# Function to plot histograms for numeric variables in a 3-wide subplot layout\n",
    "def plot_numeric_histograms_subplot(df, title_prefix=\"Distribution of\"):\n",
    "    \"\"\"\n",
    "    Plots histograms for all numeric variables in the DataFrame in a 3-wide subplot layout.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame containing numeric variables.\n",
    "    title_prefix (str): Prefix for histogram titles.\n",
    "\n",
    "    Returns:\n",
    "    None (displays a single subplot figure).\n",
    "    \"\"\"\n",
    "    # Select numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # Determine number of rows needed for 3 columns per row\n",
    "    num_cols = 3\n",
    "    num_rows = (len(numeric_columns) + num_cols - 1) // num_cols\n",
    "\n",
    "    # Create a subplot figure\n",
    "    fig = sbplt.make_subplots(rows=num_rows, cols=num_cols, subplot_titles=[f\"{title_prefix} {col}\" for col in numeric_columns])\n",
    "\n",
    "    # Add histograms to the subplots\n",
    "    for i, column in enumerate(numeric_columns):\n",
    "        row = i // num_cols + 1\n",
    "        col = i % num_cols + 1\n",
    "        histogram = go.Histogram(x=df[column], nbinsx=30, name=column)\n",
    "        fig.add_trace(histogram, row=row, col=col)\n",
    "\n",
    "    # Update layout for aesthetics\n",
    "    fig.update_layout(\n",
    "        height=num_rows * 300,  # Adjust height dynamically based on rows\n",
    "        width=1000,            # Fixed width for consistent appearance\n",
    "        title_text=\"Numeric Variable Distributions\",\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=False       # Hide legend for simplicity\n",
    "    )\n",
    "    fig.update_annotations(font_size=12)  # Adjust font size for subplot titles\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwN5p3X_PP_1",
    "outputId": "92a0ea6c-b74a-45e8-e82e-dc3903ac653e"
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_numeric_histograms_subplot(spotify_df_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GgEo40KPR0W"
   },
   "source": [
    "\n",
    "### **Bar Plots for Categorical Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Umqaa4F6PUC8"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Bar charts provide an intuitive and visually appealing way to analyze the distribution of categorical features in the dataset. This analysis focuses on the `key_`, `mode_`, and `track_genre_` features, which represent important musical attributes of tracks. By visualizing their distributions, we can gain insights into the underlying patterns of the data.\n",
    "\n",
    "#### Why Analyze These Features?\n",
    "\n",
    "1. **Key Distribution**:\n",
    "   - The `key_` features represent the musical key in which tracks are composed (e.g., C, D, G).\n",
    "   - Understanding the distribution of keys can provide insights into the musical preferences or patterns in the dataset.\n",
    "   - This analysis can reveal whether certain keys are more common, potentially reflecting trends in music production or listener preferences.\n",
    "\n",
    "2. **Mode Distribution**:\n",
    "   - The `mode_` features indicate whether a track is in a major or minor key.\n",
    "   - Visualizing the distribution of modes helps understand the emotional tone of the music, as major keys are often associated with happiness and energy, while minor keys evoke sadness or intensity.\n",
    "   - The balance between major and minor modes may reveal interesting trends in music composition.\n",
    "\n",
    "3. **Genre Distribution**:\n",
    "   - The `track_genre_` features represent the genres assigned to each track (e.g., pop, rock, jazz).\n",
    "   - Analyzing genre distribution is critical for understanding the diversity of the dataset and identifying dominant genres.\n",
    "   - This can help prioritize genres for deeper analysis or tailor models for specific use cases.\n",
    "\n",
    "#### Benefits of Visualization\n",
    "\n",
    "1. **Data Quality Checks**:\n",
    "   - Bar charts allow for quick identification of anomalies, such as missing or improperly encoded data in keys, modes, or genres.\n",
    "\n",
    "2. **Pattern Identification**:\n",
    "   - Highlights the prevalence of certain keys, modes, or genres, revealing patterns or trends that could guide further analysis.\n",
    "\n",
    "3. **Modeling Insights**:\n",
    "   - Understanding these distributions helps inform feature engineering for machine learning models.\n",
    "   - For example, imbalanced distributions may suggest a need for rebalancing or targeted modeling.\n",
    "\n",
    "4. **Actionable Insights**:\n",
    "   - Insights from these distributions can be used to tailor recommendations, prioritize popular keys or genres, and create meaningful segmentation for deeper analysis.\n",
    "\n",
    "By visualizing these features, we ensure a comprehensive understanding of the musical attributes represented in the dataset, forming the foundation for more advanced analytical tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seDLHerkPWVw"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Refactored code for having keys and modes on the first row, and genres spanning the bottom row\n",
    "def plot_categorical_bars_subplot(df, key_prefixes=['key_'], mode_prefixes=['mode_'], genre_prefixes=['track_genre_']):\n",
    "    \"\"\"\n",
    "    Creates bar charts for the counts of key_, mode_, and genre_ features with a custom layout.\n",
    "    Keys and modes are on the first row, and genres span the entire bottom row.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame containing one-hot encoded features.\n",
    "    key_prefixes (list): List of prefixes to identify key columns.\n",
    "    mode_prefixes (list): List of prefixes to identify mode columns.\n",
    "    genre_prefixes (list): List of prefixes to identify genre columns.\n",
    "\n",
    "    Returns:\n",
    "    None (displays a single subplot figure).\n",
    "    \"\"\"\n",
    "    # Identify columns based on prefixes\n",
    "    key_columns = [col for col in df.columns if any(col.startswith(prefix) for prefix in key_prefixes)]\n",
    "    mode_columns = [col for col in df.columns if any(col.startswith(prefix) for prefix in mode_prefixes)]\n",
    "    genre_columns = [col for col in df.columns if any(col.startswith(prefix) for prefix in genre_prefixes)]\n",
    "\n",
    "    # Create data for each feature type\n",
    "    key_counts = df[key_columns].sum().reset_index()\n",
    "    key_counts.columns = ['Feature', 'Count']\n",
    "    key_counts['Feature'] = key_counts['Feature'].str.replace('key_', '', regex=False)\n",
    "\n",
    "    mode_counts = df[mode_columns].sum().reset_index()\n",
    "    mode_counts.columns = ['Feature', 'Count']\n",
    "    mode_counts['Feature'] = mode_counts['Feature'].str.replace('mode_', '', regex=False)\n",
    "\n",
    "    genre_counts = df[genre_columns].sum().reset_index()\n",
    "    genre_counts.columns = ['Feature', 'Count']\n",
    "    genre_counts['Feature'] = genre_counts['Feature'].str.replace('track_genre_', '', regex=False)\n",
    "\n",
    "    # Titles for subplots\n",
    "    titles = ['Key Distribution', 'Mode Distribution', 'Genre Distribution']\n",
    "\n",
    "    # Create a subplot figure\n",
    "    fig = sbplt.make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=titles,\n",
    "        specs=[[{\"colspan\": 1}, {\"colspan\": 1}], [{\"colspan\": 2}, None]]\n",
    "    )\n",
    "\n",
    "    # Add bar charts for keys and modes in the first row\n",
    "    fig.add_trace(go.Bar(x=key_counts['Feature'], y=key_counts['Count'], name=titles[0]), row=1, col=1)\n",
    "    fig.add_trace(go.Bar(x=mode_counts['Feature'], y=mode_counts['Count'], name=titles[1]), row=1, col=2)\n",
    "\n",
    "    # Add bar chart for genres spanning the second row\n",
    "    fig.add_trace(go.Bar(x=genre_counts['Feature'], y=genre_counts['Count'], name=titles[2]), row=2, col=1)\n",
    "\n",
    "    # Update layout for aesthetics\n",
    "    fig.update_layout(\n",
    "        height=800,  # Adjust height\n",
    "        width=1200,  # Adjust width\n",
    "        title_text=\"Categorical Feature Distributions\",\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=False  # Hide legend for simplicity\n",
    "    )\n",
    "    fig.update_annotations(font_size=12)  # Adjust font size for subplot titles\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTlCA4wXPXz6",
    "outputId": "304e39aa-af97-428f-c2d2-4243e96d3a3c"
   },
   "outputs": [],
   "source": [
    "plot_categorical_bars_subplot(spotify_df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZo_SWY15cQX"
   },
   "source": [
    "# **5. Regression Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COlFRh85f3aI"
   },
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "spotify_df = spotify_df\n",
    "spotify_clean = spotify_df_cleaned.copy()\n",
    "spotify_clean['explicit'] = spotify_clean['explicit'].astype(int)\n",
    "# spotify_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsdAHXe7gIMt"
   },
   "source": [
    "A numeric response variable that we will model for regression is danceability.\n",
    "\n",
    "The single variable that we will use as a predictor is energy. We chose the response and predictor variables based on their higher correlation which makes more sense for a single linear regression model. Choosing popularity would most likely show a nonlinear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6p-nR33gF1Z",
    "outputId": "797bb4ae-a54c-4766-eccf-87c60ab9c0d6"
   },
   "outputs": [],
   "source": [
    "# Separate data frame into test, training, and validation sets\n",
    "# train = 70%, test = 15%, validation = 15%\n",
    "spotify_train, temp_data = train_test_split(spotify_clean, test_size=0.30, random_state=42)\n",
    "# Then, split the temp_data into validation and test sets\n",
    "spotify_valid, spotify_test = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(spotify_train.shape)\n",
    "print(spotify_valid.shape)\n",
    "print(spotify_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9hhk5_UgMFt"
   },
   "source": [
    "## **L1 Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rox8ub2vgOPC",
    "outputId": "6aaaf251-b6d2-4c3d-9a85-995c88130afd"
   },
   "outputs": [],
   "source": [
    "# Plot a scatter plot of energy vs danceability\n",
    "plt.scatter(spotify_train[\"energy\"], spotify_train[\"danceability\"], s = 0.1)\n",
    "plt.xlabel(\"Energy\")\n",
    "plt.ylabel(\"Danceability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRk--YRhgSBD",
    "outputId": "4abbef52-7753-4169-8489-4ff6e92ee037"
   },
   "outputs": [],
   "source": [
    "X_train = spotify_train[\"energy\"].values.reshape(-1, 1)  # Convert to 2D array\n",
    "y_train = spotify_train[\"danceability\"]\n",
    "\n",
    "model = Lasso(alpha=0, max_iter=10000)  # alpha = 0 means no regularization\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# Plot actual data\n",
    "plt.scatter(spotify_train[\"energy\"], spotify_train[\"danceability\"], s=0.1, label='data')\n",
    "\n",
    "# Plot predicted data (L1 regression line)\n",
    "plt.plot(spotify_train[\"energy\"], y_pred, color='red', label='L1 Regression Line')  # Use plot for a smooth line\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Danceability')\n",
    "plt.title('L1 Regression on Spotify Data')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YgfM7p1gW5C"
   },
   "source": [
    "The L1 regression model with no regularization appears to be underfitting the data. While it looks like there is a non-linear curve to the relationship between energy and danceability, the regression line does not capture this. Increasing the degree of the polynomial might help with reducing the underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqlxgHCsgaJi"
   },
   "source": [
    "### **L1 Metrics: MAD & MAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKT5P_szgbNW",
    "outputId": "c3cf8d3a-97a1-4dc7-dac2-aa1f11bff5f0"
   },
   "outputs": [],
   "source": [
    "#Mean Absolute Deviation (MAD)\n",
    "y_mean = np.mean(y_train)\n",
    "mad = np.mean(np.abs(y_train - y_mean))\n",
    "\n",
    "#Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "\n",
    "print(mad)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67JNGYoPgq9X"
   },
   "source": [
    "## **L2 Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "553NNDNxgtT9",
    "outputId": "e78c85d0-1a55-4cf8-ab87-e806df54b1bc"
   },
   "outputs": [],
   "source": [
    "#predictor variables\n",
    "X_train = spotify_train[\"energy\"].values.reshape(-1, 1)\n",
    "y_train = spotify_train[\"danceability\"]\n",
    "\n",
    "X_valid = spotify_valid[\"energy\"].values.reshape(-1, 1)\n",
    "y_valid = spotify_valid[\"danceability\"]\n",
    "\n",
    "#L2 regression\n",
    "ridge_model = Ridge(alpha=0.0, max_iter=10000)  # Adjust alpha if needed\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_ridge = ridge_model.predict(X_train)\n",
    "y_valid_pred_ridge = ridge_model.predict(X_valid)\n",
    "\n",
    "plt.scatter(spotify_train[\"energy\"], spotify_train[\"danceability\"], s=0.1, label='Training Data')\n",
    "plt.plot(spotify_train[\"energy\"], y_train_pred_ridge, color='red', label='Ridge Regression Line')\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Danceability')\n",
    "plt.title('Ridge Regression (L2) on Spotify Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VabENmhNgx8v"
   },
   "source": [
    "The Ridge regression line is almost flat, indicating that the model is not capturing much of the variation in danceability. The scatter of the data points suggests a more complex, non-linear relationship, but the regression line is linear and very simplistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I15mE7nxgzcH"
   },
   "source": [
    "### **L2 Metrics: rMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxynazXYg2Sa",
    "outputId": "de9a0531-bbcd-4b16-94ec-1578813f043c"
   },
   "outputs": [],
   "source": [
    "#true values\n",
    "y_train = spotify_train[\"danceability\"]\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "#residuals (errors)\n",
    "error = y_train - y_pred\n",
    "\n",
    "squared_error = error ** 2\n",
    "\n",
    "#MSE calculation\n",
    "L2_error = np.mean(squared_error)\n",
    "\n",
    "#square root for MSE\n",
    "rMSE = np.sqrt(L2_error)\n",
    "\n",
    "print(\"rMSE:\", rMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXiwcGDvg4io"
   },
   "source": [
    "Since both L1 and L2 regression models appear to be underfitting the data and scatter plots suggest a non-linear relationship between energy and danceability, regularization is not necessary. Regularization is primarily a technique to prevent overfitting, not underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3Vx8oMN5bS3"
   },
   "source": [
    "## **Logistic Regression Analysis**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53dYgCEziSXT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1a4NRXfigR8"
   },
   "source": [
    "### **Binary Categorical Response Variable/Predictor Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWdy_ty1ijp0"
   },
   "source": [
    "The binary categorical response variable we chose was explicitness. We wanted to determine whether speechiness, our predictor variable, could predict whether a song was explicit. We believe that there may be a relationship since rap songs are usually more speechy and tend to be more explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEJpy0IEi5pX"
   },
   "outputs": [],
   "source": [
    "spotify_train, temp_data = train_test_split(spotify_clean, test_size=0.40, random_state=42)\n",
    "\n",
    "spotify_valid, spotify_test = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = spotify_train[[\"speechiness\"]]\n",
    "y_train = spotify_train[\"explicit\"]\n",
    "\n",
    "X_val = spotify_valid[[\"speechiness\"]]\n",
    "y_val = spotify_valid[\"explicit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfipJIh3i-O2"
   },
   "source": [
    "### **Modeling Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0xN5yJDi_nH",
    "outputId": "0489517d-4b18-4813-e8b4-82121be72dd6"
   },
   "outputs": [],
   "source": [
    "# Binary response variable = explicitness\n",
    "# Initialize the logistic regression model\n",
    "lr_all = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Fit the model\n",
    "lr_all.fit(X_train, y_train)\n",
    "\n",
    "# Get the intercept and coefficients\n",
    "intercept = lr_all.intercept_\n",
    "coefficients = lr_all.coef_\n",
    "\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"Coefficients:\", coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3Jnr3-3jQ9T",
    "outputId": "5a8ae82d-2906-4d30-d91e-7166c465c95a"
   },
   "outputs": [],
   "source": [
    "pred_val_sample = pd.DataFrame(dict(\n",
    "    explicit=y_val,  # Use y_val for actual values\n",
    "    lr_predict=lr_all.predict_proba(X_val)[:, 1],  # Predicted probabilities\n",
    "    lr_predict_binary=lr_all.predict(X_val)  # Binary predictions\n",
    "))\n",
    "pred_val_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSVH0YxFbQ5Z",
    "outputId": "c3b86521-936c-4bb0-f852-2cff14deb5fd"
   },
   "outputs": [],
   "source": [
    "# Generate predictions over a range of speechiness values\n",
    "speechiness_range = np.linspace(0, 1, 300).reshape(-1, 1)\n",
    "predicted_probabilities = lr_all.predict_proba(speechiness_range)[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training data\n",
    "plt.scatter(X_train, y_train, color='blue', alpha=0.6, label='Training Data')\n",
    "\n",
    "# Plot validation data with predicted probabilities\n",
    "plt.scatter(X_val, y_val, color='green', alpha=0.6, label='Validation Data')\n",
    "plt.scatter(X_val, pred_val_sample['lr_predict'], color='orange', marker='x', label='Predicted Probabilities')\n",
    "\n",
    "plt.plot(speechiness_range, predicted_probabilities, color='red', linewidth=2, label='Logistic Regression Curve')\n",
    "\n",
    "plt.xlabel('Speechiness')\n",
    "plt.ylabel('Probability of Being Explicit')\n",
    "plt.title('Logistic Regression Model: Speechiness vs. Explicitness')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOk3mgY9eKCP"
   },
   "source": [
    "The curve shows a clear positive relationship between speechiness and the likelihood of a song being explicit. This supports the hypothesis that songs with higher speechiness (e.g., rap songs) are more likely to be explicit.\n",
    "\n",
    "Around a speechiness value of 0.5 to 0.6, the probability of being explicit starts to exceed 50%.\n",
    "\n",
    "The predictions generally align well with the data points, indicating that the logistic regression model captures the trend effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbJHysj1jXZh"
   },
   "source": [
    "### **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mXWyemyjZGM",
    "outputId": "91bb505c-2505-419a-8e1a-c8d4f7db4573"
   },
   "outputs": [],
   "source": [
    "conf_lr = metrics.confusion_matrix(y_true=pred_val_sample['explicit'],\n",
    "                                   y_pred=pred_val_sample['lr_predict_binary'])\n",
    "conf_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqIvFH2LgL_P"
   },
   "source": [
    "The model struggles to correctly identify explicit songs, as shown by the 1,432 false negatives.\n",
    "\n",
    "The model rarely misclassifies non-explicit songs as explicit (only 70 instances)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1ZQ8hZ4jh3e"
   },
   "source": [
    "### **Prediction Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-7z0-BTjkPa",
    "outputId": "d75c4523-0611-4d54-cbfc-3cc99fa35b25"
   },
   "outputs": [],
   "source": [
    "# (conf_lr[0, 0] + conf_lr[1, 1]) / conf_lr.sum()\n",
    "pred_acc = metrics.accuracy_score(y_true=pred_val_sample['explicit'],\n",
    "                       y_pred=pred_val_sample['lr_predict_binary'])\n",
    "\n",
    "pred_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Fu_I02Bjnpl"
   },
   "source": [
    "### **Prediction Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnqL6i8Njp-q",
    "outputId": "d1655e40-3589-44ec-8cf0-9f79764dbfd9"
   },
   "outputs": [],
   "source": [
    "pred_err = 1 - pred_acc\n",
    "pred_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xk9k3Sojt75"
   },
   "source": [
    "### **True Positive Rate (Sensitivity/Recall)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDY32z6rjxqU",
    "outputId": "e1b30fdc-d99e-43c8-a03d-911f4cf4cd4a"
   },
   "outputs": [],
   "source": [
    "# (conf_lr[1, 1]) / conf_lr[1,:].sum()\n",
    "tpr = metrics.recall_score(y_true=pred_val_sample['explicit'],\n",
    "                     y_pred=pred_val_sample['lr_predict_binary'])\n",
    "print(tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpqpzQWmgbJS"
   },
   "source": [
    "The model is only correctly identifying about 6.5% of the actual explicit songs.\n",
    "\n",
    "This may suggest that there may be far more non-explicit songs than explicit ones in the dataset, leading to a bias toward predicting the majority class (non-explicit). The model might also be overly conservative when predicting explicit songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKJc-_Ysj28L"
   },
   "source": [
    "### **True Negative Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H81w7m6_j-VR",
    "outputId": "82cea953-4030-4eab-98a2-0191d8584d62"
   },
   "outputs": [],
   "source": [
    "# (conf_lr[0, 0]) / conf_lr[0,:].sum()\n",
    "tnr = metrics.recall_score(y_true=pred_val_sample['explicit'],\n",
    "                     y_pred=pred_val_sample['lr_predict_binary'],\n",
    "                     pos_label=0)\n",
    "print(tnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-rd8R3Qg0cJ"
   },
   "source": [
    "The model correctly identifies 99.57% of the non-explicit songs. It is excellent at identifying non-explicit songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Und8G6ptkEop"
   },
   "source": [
    "### **ROC Curve**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX45hMBMkF2q"
   },
   "source": [
    "ROC curves plot true positive rates against true negative rates to compare models and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCwawibOkJ6x",
    "outputId": "1f7d4a57-cbd2-45ce-a096-86069ccac591"
   },
   "outputs": [],
   "source": [
    "lr_fpr_sample, lr_tpr_sample, lr_thresholds_sample = metrics.roc_curve(pred_val_sample['explicit'], pred_val_sample['lr_predict'])\n",
    "lr_thresholds_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWtiKnI4kPgs",
    "outputId": "1590c6b8-db49-47ac-bcf8-684f75802ec8"
   },
   "outputs": [],
   "source": [
    "roc_lr_sample = pd.DataFrame({\n",
    "    'False Positive Rate': lr_fpr_sample,\n",
    "    'True Positive Rate': lr_tpr_sample,\n",
    "    'Model': 'Logistic Regression'\n",
    "}, index=lr_thresholds_sample)\n",
    "\n",
    "\n",
    "roc_sample_df = pd.concat([roc_lr_sample])\n",
    "\n",
    "\n",
    "px.line(roc_sample_df, y='True Positive Rate', x='False Positive Rate',\n",
    "        color='Model',\n",
    "        width=700, height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5l9sSS_smxvS"
   },
   "source": [
    "The curve suggests that the model performs reasonably well but not perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ys9DCkpHkUgl"
   },
   "source": [
    "### **AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "989kR6pSkVgD",
    "outputId": "a689e8d0-19ee-4c93-9714-99d58fb364ec"
   },
   "outputs": [],
   "source": [
    "lr_auc_sample = metrics.roc_auc_score(pred_val_sample['explicit'], pred_val_sample['lr_predict'])\n",
    "print('Logistic regression AUC:', lr_auc_sample.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSm4EWhxnWID"
   },
   "source": [
    "AUC = 0.763 indicates that the model has a fair performance in distinguishing between explicit and non-explicit songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8rukhjYkbQZ"
   },
   "source": [
    "## **Cross-Fold Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6L3HbJ96kgSD",
    "outputId": "f9852985-86f6-4590-f7cd-8e77f5026a63"
   },
   "outputs": [],
   "source": [
    "# This does stratified Kfolds for us...\n",
    "roc_auc_scores = cross_val_score(lr_all, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fVRNv8vkjBJ",
    "outputId": "c2ece400-4bb5-4745-8127-c1dee68a127c"
   },
   "outputs": [],
   "source": [
    "# Use the shuffle and random state if want data shuffled before splitting\n",
    "X = spotify_train[[\"speechiness\"]]  # Feature set\n",
    "y = spotify_train[\"explicit\"]        # Target variable\n",
    "skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in skfolds.split(X, y):\n",
    "    clone_lr = clone(lr_all)  # Clone the model to avoid fitting multiple times\n",
    "    X_train_folds = X.iloc[train_index]\n",
    "    y_train_folds = y.iloc[train_index]\n",
    "    X_test_fold = X.iloc[test_index]\n",
    "    print(\"Test indices for fold:\", test_index)\n",
    "    clone_lr.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_lr.predict(X_test_fold)\n",
    "\n",
    "    # Calculate AUC and Accuracy\n",
    "    auc_sample = metrics.roc_auc_score(y.iloc[test_index], y_pred)\n",
    "    accuracy_sample = metrics.accuracy_score(y.iloc[test_index], y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print('Fold: ', i)\n",
    "    print('AUC: ', auc_sample)\n",
    "    print('Accuracy: ', accuracy_sample)\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0M3568CJoSdf"
   },
   "source": [
    "The AUC values are consistently low, around 0.53 to 0.54. The model is barely better than random chance at distinguishing explicit songs from non-explicit ones during each fold.\n",
    "\n",
    "The accuracy is consistently high, around 91.4% to 91.7%. This reflects the class imbalance in the dataset, where the majority class (non-explicit) dominates predictions. The model's high accuracy likely comes from predicting most songs as non-explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_E_mZPYkmYa"
   },
   "source": [
    "### **Threshold for positive predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LmdQ70GkpfW",
    "outputId": "bba366d3-d2a2-44aa-e023-fb038424674e"
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for train_index, test_index in skfolds.split(X, y):\n",
    "    clone_lr = clone(lr_all)  # Clone the model to avoid fitting multiple times\n",
    "    X_train_folds = X.iloc[train_index]\n",
    "    y_train_folds = y.iloc[train_index]\n",
    "    X_test_fold = X.iloc[test_index]\n",
    "\n",
    "    clone_lr.fit(X_train_folds, y_train_folds)  # Fit the model\n",
    "    y_pred_proba = clone_lr.predict_proba(X_test_fold)[:, 1]  # Get predicted probabilities for the positive class\n",
    "\n",
    "    # Calculate the median threshold from predicted probabilities\n",
    "    median_threshold = np.median(y_pred_proba)\n",
    "\n",
    "    # Classify based on the median of predicted probabilities\n",
    "    y_pred = (y_pred_proba >= median_threshold).astype(int)\n",
    "\n",
    "    # Calculate AUC and Accuracy\n",
    "    auc_sample = metrics.roc_auc_score(y.iloc[test_index], y_pred_proba)\n",
    "    accuracy_sample = metrics.accuracy_score(y.iloc[test_index], y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print('Fold: ', i)\n",
    "    print('Median Threshold: ', median_threshold)\n",
    "    print('AUC: ', auc_sample)\n",
    "    print('Accuracy: ', accuracy_sample)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx62aIeYpQxQ"
   },
   "source": [
    "The median threshold for classification is consistently low (around 0.060), indicating that the predicted probabilities for explicit songs are generally low.\n",
    "\n",
    "The AUC scores range between 0.769 and 0.785, showing a moderate improvement compared to the previous results (around 0.53).\n",
    "\n",
    "This suggests the model's ability to distinguish between explicit and non-explicit songs has improved.\n",
    "\n",
    "The accuracy scores are now much lower (around 55.5% to 55.9%) compared to the previous 91%.\n",
    "\n",
    "This drop in accuracy is due to the model now predicting more explicit songs, addressing the class imbalance but sacrificing overall accuracy for better balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qt2o_LjokyIX"
   },
   "source": [
    "The two thresholds that we tested were 0.5 (default) and the median of speechiness. In the first instance, we had a very high accuracy (0.914 to 0.917) but a very low AUC score (0.536 to 0.538). Area under the curve scores indicate whether a model is doing well at predicting, and since the AUC scores were close to 0.5, this indicates that our model was essentially guessing.\n",
    "\n",
    "When we changed the threshold to the median of the predicted probabilities of whether a song was explicit or not, there was a higher AUC score (0.769 - 0.784) and a low accuracy score (0.555 - 0.559). Although the accuracy was low, we figured that AUC would be a better metric since upon further evaluation above, our dataset has class imbalances (more not explicit than explicit). Therefore, we thought that choosing the median of the predicted probabilities as the threshold would be the best option since it best manages class imbalances. By choosing this as our threshold, we were able to increase our AUC score. (The accuracy may be improved by reducing class imbalances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJ_apJv7ubpq"
   },
   "source": [
    "### **Using the class_weight='balanced' parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jAn8D7wiMg2",
    "outputId": "9b449e2f-75e6-4514-de09-af7aa5339d68"
   },
   "outputs": [],
   "source": [
    "# count the number of explicit and non-explicit songs in the dataset\n",
    "explicit_counts = spotify_clean['explicit'].value_counts()\n",
    "\n",
    "# calculate the percentage distribution of each class\n",
    "explicit_percentage = spotify_clean['explicit'].value_counts(normalize=True) * 100\n",
    "\n",
    "explicit_counts, explicit_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUi-5YJfif27"
   },
   "source": [
    "Class distribution in the dataset:\n",
    "Non-explicit songs (0): 82,036 (91.42%)\n",
    "Explicit songs (1): 7,704 (8.58%)\n",
    "\n",
    "There is a significant class imbalance in the dataset, with far more non-explicit songs (91.4%) than explicit songs (8.6%). This imbalance leads to the model being biased towards predicting non-explicit songs more frequently.\n",
    "\n",
    "We will try to use the class_weight='balanced' parameter in LogisticRegression to handle imbalance later. Non-explicit songs (majority class) get a lower weight while explicit songs (minority class) get a higher weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETF0Nnp7kYMr",
    "outputId": "149ca20f-2fc8-4448-f136-0d0d7a09a172"
   },
   "outputs": [],
   "source": [
    "# Binary response variable = explicitness\n",
    "# Initialize the logistic regression model\n",
    "lr_all = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "\n",
    "# Fit the model\n",
    "lr_all.fit(X_train, y_train)\n",
    "\n",
    "# Get the intercept and coefficients\n",
    "intercept = lr_all.intercept_\n",
    "coefficients = lr_all.coef_\n",
    "\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"Coefficients:\", coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40KnF6b9krr3",
    "outputId": "e699906d-9d87-4974-9d6f-f432cfc52c22"
   },
   "outputs": [],
   "source": [
    "pred_val_sample = pd.DataFrame(dict(\n",
    "    explicit=y_val,  # Use y_val for actual values\n",
    "    lr_predict=lr_all.predict_proba(X_val)[:, 1],  # Predicted probabilities\n",
    "    lr_predict_binary=lr_all.predict(X_val)  # Binary predictions\n",
    "))\n",
    "pred_val_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1UcuD8d9kgHp",
    "outputId": "fc6b22f7-b3e1-467a-e598-83a017ca96dd"
   },
   "outputs": [],
   "source": [
    "# Generate predictions over a range of speechiness values\n",
    "speechiness_range = np.linspace(0, 1, 300).reshape(-1, 1)\n",
    "predicted_probabilities = lr_all.predict_proba(speechiness_range)[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training data\n",
    "plt.scatter(X_train, y_train, color='blue', alpha=0.6, label='Training Data')\n",
    "\n",
    "# Plot validation data with predicted probabilities\n",
    "plt.scatter(X_val, y_val, color='green', alpha=0.6, label='Validation Data')\n",
    "plt.scatter(X_val, pred_val_sample['lr_predict'], color='orange', marker='x', label='Predicted Probabilities')\n",
    "\n",
    "plt.plot(speechiness_range, predicted_probabilities, color='red', linewidth=2, label='Logistic Regression Curve')\n",
    "\n",
    "plt.xlabel('Speechiness')\n",
    "plt.ylabel('Probability of Being Explicit')\n",
    "plt.title('Logistic Regression Model: Speechiness vs. Explicitness')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wdUwxTtkzZi"
   },
   "source": [
    "The red logistic curve reaches a probability of 1 very quickly and stays flat across half of the speechiness range, suggesting that the model is predicting a high probability of explicitness for most speechiness values.\n",
    "\n",
    "The orange crosses (predicted probabilities) follow the red curve closely and also saturate near 1. This shows that the model is biased toward predicting high probabilities of explicitness.\n",
    "\n",
    "Even with class_weight='balanced', the model still struggles with the severe imbalance, causing it to predict explicitness frequently.\n",
    "\n",
    "The default decision threshold of 0.5 might not be suitable for this dataset. Explicit predictions might need a higher threshold to balance sensitivity and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ns0uG5PyqLei",
    "outputId": "1bdd9394-5e3d-4877-d971-a439b55934c2"
   },
   "outputs": [],
   "source": [
    "y_val_pred = lr_all.predict(X_val)\n",
    "y_val_proba = lr_all.predict_proba(X_val)[:, 1]\n",
    "\n",
    "conf_matrix = metrics.confusion_matrix(y_true=y_val, y_pred=y_val_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_val, y_pred=y_val_pred)\n",
    "\n",
    "sensitivity = metrics.recall_score(y_true=y_val, y_pred=y_val_pred)\n",
    "\n",
    "specificity = metrics.recall_score(y_true=y_val, y_pred=y_val_pred, pos_label=0)\n",
    "\n",
    "conf_matrix, accuracy, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmA6c8KkuY4W"
   },
   "source": [
    "The sensitivity (49.67%) is significantly better compared to the earlier value (around 6%). The specificity remains relatively high at 85.52%.\n",
    "\n",
    "The model is now better at identifying explicit songs but still struggles with false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6rBaoeHusLA",
    "outputId": "da6fb3d7-dc2d-49fc-9313-22f6120fa16e"
   },
   "outputs": [],
   "source": [
    "auc_with_balanced = metrics.roc_auc_score(y_true=y_val, y_score=y_val_proba)\n",
    "auc_with_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDHNEc_6u9r_"
   },
   "source": [
    "This AUC score indicates that the model with class weighting achieves 76.3% in distinguishing between explicit and non-explicit songs. This is consistent with the previous AUC score when class weights were not balanced.\n",
    "\n",
    "The model now balances sensitivity and specificity better, even though the overall accuracy is slightly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ubdzwj8vO_W",
    "outputId": "e10c291d-7f4d-4824-8180-55fb520e4091"
   },
   "outputs": [],
   "source": [
    "y_val_proba = lr_all.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Initialize a range of thresholds from 0 to 1\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_val_pred_tuned = (y_val_proba >= threshold).astype(int)\n",
    "    sensitivities.append(metrics.recall_score(y_val, y_val_pred_tuned))\n",
    "    specificities.append(metrics.recall_score(y_val, y_val_pred_tuned, pos_label=0))\n",
    "\n",
    "# Find the threshold that balances sensitivity and specificity\n",
    "best_threshold_index = np.argmin(np.abs(np.array(sensitivities) - np.array(specificities)))\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "\n",
    "best_threshold, sensitivities[best_threshold_index], specificities[best_threshold_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX-DN_avvlsA"
   },
   "source": [
    "Best threshold: 0.404 This threshold achieves a balance between sensitivity and specificity.\n",
    "\n",
    "At optimal threshold:\n",
    "\n",
    "Sensitivity (True Positive Rate): 68.28%\n",
    "\n",
    "Specificity (True Negative Rate): 71.33%\n",
    "\n",
    "Using class_weight='balanced' improves sensitivity significantly. We have good model performance since the AUC score remains 0.763. Additionally, by adjusting the threshold to 0.404, we achieve a better balance between sensitivity and specificity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kg2bOamLJ_vJ"
   },
   "source": [
    "# **6. KNN/Decision Trees/Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpHU1bGYe323"
   },
   "source": [
    "## K-Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkZHnPz8ehiR"
   },
   "outputs": [],
   "source": [
    "spotify_clean = spotify_df_cleaned.copy()\n",
    "pop_labels = [1 if x >= 50 else 0 for x in spotify_clean[\"popularity\"]]\n",
    "spotify_clean['popularity'] = [1 if x >= 30 else 0 for x in spotify_clean[\"popularity\"]]\n",
    "spotify_clean['explicit'] = spotify_clean['explicit'].astype(int)\n",
    "spotify_clean = spotify_clean.iloc[:,:20]\n",
    "# Split the data into training, validation, and test sets\n",
    "spotify_train, spotify_valid = train_test_split(spotify_clean, test_size=0.2, random_state=42)\n",
    "spotify_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15HcufS4ej47"
   },
   "outputs": [],
   "source": [
    "X_train = spotify_train[[\"danceability\", \"speechiness\"]]\n",
    "y_train = spotify_train[\"popularity\"]\n",
    "X_val = spotify_valid[[\"danceability\", \"speechiness\"]]\n",
    "y_val = spotify_valid[\"popularity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7jya2x_emEw"
   },
   "outputs": [],
   "source": [
    "# 1. Initialize and Train the KNN Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # You can adjust 'n_neighbors' based on model performance\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation data\n",
    "knn_predictions = knn_model.predict(X_val)\n",
    "knn_probabilities = knn_model.predict_proba(X_val)[:, 1]  # Probability for the positive class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvR9ui2SetEX"
   },
   "outputs": [],
   "source": [
    "# 2. Calculate Confusion Matrix, Prediction Accuracy, Prediction Error, TPR, TNR, and F1 Score\n",
    "conf_matrix = confusion_matrix(y_val, knn_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "accuracy = accuracy_score(y_val, knn_predictions)\n",
    "error = 1 - accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Error:\", error)\n",
    "\n",
    "tpr = recall_score(y_val, knn_predictions)\n",
    "tnr = recall_score(y_val, knn_predictions, pos_label=0)\n",
    "print(\"True Positive Rate:\", tpr)\n",
    "print(\"True Negative Rate:\", tnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3bOZzlAetsI"
   },
   "outputs": [],
   "source": [
    "# 3. Calculate and Plot ROC Curve and AUC on Validation Set using 5-Fold Cross-Validation\n",
    "fpr, tpr, thresholds = roc_curve(y_val, knn_probabilities)\n",
    "plt.plot(fpr, tpr, label=\"K-Nearest Neighbors\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for KNN Model\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_val, knn_probabilities)\n",
    "print(\"AUC Score:\", auc)\n",
    "\n",
    "# 5-Fold Cross-Validation for AUC\n",
    "cv_auc = cross_val_score(knn_model, X_train, y_train, cv=5, scoring=\"roc_auc\")\n",
    "print(\"5-Fold Cross-Validation AUC Scores:\", cv_auc)\n",
    "print(\"Average AUC Score:\", cv_auc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LONmgdllezHl"
   },
   "source": [
    "## Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9FFrsrWewjO"
   },
   "outputs": [],
   "source": [
    "features = ['duration_ms',\t'explicit',\t'danceability',\t'energy',\t'loudness',\t'speechiness',\t'acousticness',\t'instrumentalness',\t'liveness',\t'valence',\t'tempo']\n",
    "\n",
    "X = spotify_clean[features]\n",
    "y = spotify_clean['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nApyuSCe7Ye"
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJpxBx3ge9XK"
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-c9Q78Te-w6"
   },
   "outputs": [],
   "source": [
    "y_val_pred = rf_model.predict(X_val)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "y_test_prob = rf_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPN0j78PfAKE"
   },
   "outputs": [],
   "source": [
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "print(f'Validation MSE: {val_mse}')\n",
    "print(f'Test MSE: {test_mse}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test AUC: {test_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqMcnc20fCJv"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {test_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2dzQl2LJ6UK"
   },
   "source": [
    "# **7. PCA & Clustering**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pjcu3xQE3dJ",
    "outputId": "d0d8d2c2-2872-41bc-a3b2-45fd378bba6f"
   },
   "outputs": [],
   "source": [
    "spotify_clean = spotify_df_cleaned.copy()\n",
    "print(spotify_clean.shape)\n",
    "spotify_clean['explicit'] = spotify_clean['explicit'].astype(int)\n",
    "\n",
    "y_labels = [1 if x >= 50 else 0 for x in spotify_clean[\"popularity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfiTT8pPFHUu",
    "outputId": "3ded177d-d38c-45b3-aa33-1eb499cbd440"
   },
   "outputs": [],
   "source": [
    "pca_features = spotify_clean[[\"speechiness\", \"danceability\", \"energy\", \"valence\", \"tempo\", \"loudness\", \"acousticness\"]]\n",
    "pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3Q9VVEEFLd1",
    "outputId": "8d1ffb14-57cd-415e-c5c5-9dfb5ec9c8a5"
   },
   "outputs": [],
   "source": [
    "# Standardize data (scale/mean-center)\n",
    "std_scaler = StandardScaler()\n",
    "spotify_scaled = std_scaler.fit_transform(pca_features.to_numpy())\n",
    "spotify_scaled = pd.DataFrame(spotify_scaled, columns = [\"speechiness\", \"danceability\", \"energy\", \"valence\", \"tempo\", \"loudness\", \"acousticness\"])\n",
    "print(f'Speechiness mean: {spotify_scaled[\"speechiness\"].mean()}')\n",
    "print(f'Speechiness standard deviation: {spotify_scaled[\"speechiness\"].std()}')\n",
    "print(spotify_scaled.shape)\n",
    "\n",
    "spotify_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPUZIc2UFMFj",
    "outputId": "9ad2fb42-cd20-429a-fde3-d598f4a452b0"
   },
   "outputs": [],
   "source": [
    "# Visualize distribution of variables\n",
    "for column in spotify_scaled.columns:\n",
    "    sns.histplot(spotify_scaled[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nd5QWJeuFN2I",
    "outputId": "9ac3ef4d-dfdc-4d6b-d99d-282bc0f0810a"
   },
   "outputs": [],
   "source": [
    "# Perform SVD\n",
    "pca_U, pca_d, pca_V = np.linalg.svd(spotify_scaled, full_matrices = False)\n",
    "print(f'Singular values matrix shape: {pca_d.shape}')\n",
    "print(f'Right singular vectors shape: {pca_V.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUoviwkPFWdq",
    "outputId": "6ed747be-b08c-467a-801c-f74de9838491"
   },
   "outputs": [],
   "source": [
    "prop_var = np.square(pca_d) / sum(np.square(pca_d))\n",
    "spotify_pcs = pd.DataFrame(\n",
    "    {\"PC\": 1 + np.arange(0, prop_var.shape[0]),\n",
    "     \"variability_explained\": prop_var.round(2),\n",
    "     \"cumulative_variability_explained\": prop_var.cumsum().round(2)\n",
    "     })\n",
    "\n",
    "spotify_pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UI08OwfvFYqu",
    "outputId": "3eb24112-131a-4d2b-b31d-31f157604409"
   },
   "outputs": [],
   "source": [
    "# Plot scree plot to determine number of PCs to keep\n",
    "plt.plot(spotify_pcs[\"PC\"], spotify_pcs[\"variability_explained\"])\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Proportion of Variance Explained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsEnADggFaRv",
    "outputId": "77fd83ff-a063-4c26-a7b7-53dcfd137fd6"
   },
   "outputs": [],
   "source": [
    "# View PC1\n",
    "loadings1 = pd.DataFrame(\n",
    "    {\"feature\": spotify_scaled.columns,\n",
    "     \"pc1_loading\": pca_V[0]\n",
    "     })\n",
    "# look at the 10 largest (absolute value) loadings for PC1 but print out the signed value\n",
    "loadings1.reindex(loadings1[\"pc1_loading\"].abs().sort_values(ascending=False).index) \\\n",
    "    .head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3wgOZWAFdI0",
    "outputId": "6da366dd-31e2-4591-a3b0-084e62e4253b"
   },
   "outputs": [],
   "source": [
    "# View PC2\n",
    "loadings2 = pd.DataFrame(\n",
    "    {\"feature\": spotify_scaled.columns,\n",
    "     \"pc2_loading\": pca_V[2]\n",
    "     })\n",
    "# look at the 10 largest (absolute value) loadings for PC2 but print out the signed value\n",
    "loadings2.reindex(loadings2[\"pc2_loading\"].abs().sort_values(ascending=False).index) \\\n",
    "    .head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xla-HzPkFfOo",
    "outputId": "bc965594-0c36-4025-f957-934f58d955c5"
   },
   "outputs": [],
   "source": [
    "# Project data onto PCs and plot\n",
    "pca_scaled_spotify = spotify_scaled@pca_V.T\n",
    "pca_scaled_spotify.columns = [\"PC\" + str(1+col) for col in pca_scaled_spotify.columns]\n",
    "pca_scaled_spotify = pd.concat([pd.DataFrame(y_labels), pca_scaled_spotify], axis = 1)\n",
    "pca_scaled_spotify.rename(columns={0: 'train_labels'}, inplace=True)\n",
    "\n",
    "px.scatter(pca_scaled_spotify, x=\"PC1\", y=\"PC2\", color = \"train_labels\",\n",
    "           hover_name = spotify_scaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFY09S3QFkhH",
    "outputId": "99f56f19-f1d0-4050-afe8-628c35ad0d1e"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "clustering_sample = pca_scaled_spotify.sample(10000)\n",
    "clustering_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXjSsq5hFpRp",
    "outputId": "26580651-9cec-473f-dee2-43e52458fce3"
   },
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering\n",
    "hclust = AgglomerativeClustering(metric = 'euclidean', linkage = 'ward',n_clusters = 2)\n",
    "hclust_labels = hclust.fit(clustering_sample[1:]).labels_\n",
    "for i in range(6):\n",
    "    # print(np.where(body_hclust_labels == i))\n",
    "    print(f\"Number of data points in cluster {i}: {len(np.where(hclust_labels == i)[0])}\")\n",
    "\n",
    "print(f\"Silhouette score for hiearchical clustering: {silhouette_score(clustering_sample[1:], hclust_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BV1fo00XFqhf",
    "outputId": "4c98f8cd-1350-4c59-ba13-43e0ba5b8c5e"
   },
   "outputs": [],
   "source": [
    "# Perform kmeans clustering\n",
    "kmeans = KMeans(n_clusters = 2) # kmeans.labels gets the cluster label for each data point\n",
    "# Fit_predict computes cluster centers and predicts cluster index for each sample (returns cluster labels for each data point)\n",
    "y_kmeans = kmeans.fit_predict(clustering_sample[1:])\n",
    "kmeans.cluster_centers_ # Big arrays b/c centroid is multidimensional on hundreds of features\n",
    "kmeans_labels = kmeans.labels_\n",
    "# Examine the clusters\n",
    "for i in range(20):\n",
    "    # print(np.where(body_hclust_labels == i))\n",
    "    print(f\"Number of data points in cluster {i}: {len(np.where(y_kmeans == i)[0])}\")\n",
    "\n",
    "print(f\"Silhouette score for K-means: {silhouette_score(clustering_sample[1:], y_kmeans)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I31sE5BZFxUu",
    "outputId": "8044814b-9852-49a9-a6d3-d6cb18020279"
   },
   "outputs": [],
   "source": [
    "# Calculate rand index\n",
    "print(f\"Rand score for K-means and hierarchical clustering: {rand_score(y_kmeans, hclust_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Keor9Y8QF2AA",
    "outputId": "81b9f293-4cb6-46e6-fab0-30da252e4d73"
   },
   "outputs": [],
   "source": [
    "# Creating a single plot with the colors\n",
    "clustering_sample = pd.concat([pd.DataFrame(kmeans_labels), clustering_sample], axis = 1)\n",
    "clustering_sample.rename(columns={0: 'kmeans_labels'}, inplace=True)\n",
    "\n",
    "clustering_sample = pd.concat([pd.DataFrame(hclust_labels), clustering_sample], axis = 1)\n",
    "clustering_sample.rename(columns={0: 'hclust_labels'}, inplace=True)\n",
    "\n",
    "# Plot 1 row, 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize = (18, 6))\n",
    "scatter1 = axes[0].scatter(x=clustering_sample['PC1'], y=clustering_sample['PC2'], c = clustering_sample['train_labels'])\n",
    "axes[0].set_title(\"i) Activity Label\")\n",
    "axes[0].set_xlabel(\"PC1\")\n",
    "axes[0].set_ylabel(\"PC2\")\n",
    "\n",
    "scatter1 = axes[1].scatter(x=clustering_sample['PC1'], y=clustering_sample['PC2'], c = clustering_sample['kmeans_labels'])\n",
    "axes[1].set_title(\"ii) Kmeans Clustering Label\")\n",
    "axes[1].set_xlabel(\"PC1\")\n",
    "axes[1].set_ylabel(\"PC2\")\n",
    "\n",
    "scatter1 = axes[2].scatter(x=clustering_sample['PC1'], y=clustering_sample['PC2'], c = clustering_sample['hclust_labels'])\n",
    "axes[2].set_title(\"iii) Hierarchical Clustering Label\")\n",
    "axes[2].set_xlabel(\"PC1\")\n",
    "axes[2].set_ylabel(\"PC2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnvObTQ42CvZ"
   },
   "source": [
    "# **8. Neural Networks**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HI7dE0UQ2T0o",
    "outputId": "62ac7817-89ce-4b14-a1fa-132c7848d1a6"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "spotify_clean = spotify_df_cleaned.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7cTSaIW2WpH",
    "outputId": "2c28db25-3325-4448-b934-5d0721c4ca3a"
   },
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = spotify_clean[[\"speechiness\", \"danceability\", \"energy\", \"valence\", \"tempo\", \"loudness\", \"acousticness\"]]\n",
    "target = 'popularity'\n",
    "\n",
    "#before converting into binary values\n",
    "sns.histplot(spotify_clean[target], kde= True)\n",
    "plt.show()\n",
    "unique_counts = spotify_clean[target].nunique()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1ZWaqYJ2YD-",
    "outputId": "39d43264-c714-4275-9b65-d123a0773c6e"
   },
   "outputs": [],
   "source": [
    "target = (spotify_clean[\"popularity\"] > 50).astype(int)  # set popularity threshold at\n",
    "\n",
    "# Plot popularity distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(target, bins=2, alpha=0.7, color='green', edgecolor='black', rwidth=0.8)\n",
    "plt.xticks([0, 1], labels=['Not Popular', 'Popular'])\n",
    "plt.xlabel(\"Popularity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Popularity Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhBIisxC2YnY"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WDngXgr2bEJ"
   },
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7K3n5h42cXQ"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiZ_KER32dud"
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class SpotifyClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(SpotifyClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RwXIU6o2GQ7"
   },
   "source": [
    "## **HyperParameters**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRbiBjOY2RYZ"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 16  # Adjust as needed\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7TLoGTZ2l2A"
   },
   "source": [
    "Training Neural Network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zzmq-lZ2hS3"
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = SpotifyClassifier(input_dim, hidden_dim)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLcOI0t12scc",
    "outputId": "bf1e38e9-9c56-4696-a6a7-1b67a18199d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to store loss values\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop with validation loss tracking\n",
    "for epoch in range(num_epochs):\n",
    "   # Training\n",
    "   model.train()\n",
    "   optimizer.zero_grad()\n",
    "   train_outputs = model(X_train)\n",
    "   train_loss = criterion(train_outputs, y_train)\n",
    "   train_loss.backward()\n",
    "   optimizer.step()\n",
    "\n",
    "\n",
    "   # Validation\n",
    "   model.eval()\n",
    "   with torch.no_grad():\n",
    "       val_outputs = model(X_test)\n",
    "       val_loss = criterion(val_outputs, y_test)\n",
    "\n",
    "\n",
    "   # Store the losses\n",
    "   train_losses.append(train_loss.item())\n",
    "   val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "   if (epoch + 1) % 10 == 0:\n",
    "       print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    " # Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    predictions = (predictions > 0.5).float()\n",
    "    accuracy = (predictions.eq(y_test).sum() / y_test.shape[0]).item()\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBITqVj42uTb",
    "outputId": "87bc88d2-6505-414f-a6f9-8367e88483a1"
   },
   "outputs": [],
   "source": [
    "# Plot training vs. validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "M-ZTAN8pNVG0",
    "OOm7K3FjNkjN",
    "S6R7nV2bOJP9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
